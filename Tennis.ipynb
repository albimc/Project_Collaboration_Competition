{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import inspect\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check Progress\n",
    "from tensorboardX import SummaryWriter\n",
    "import progressbar as pb\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis_Linux_NoVis/Tennis.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "print (brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      "The state for the second agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.4669857  -1.5\n",
      "  0.          0.         -6.83172083  6.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "print('The state for the second agent looks like:', states[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 0: 0.0000\n",
      "Score (max over agents) from episode 1: 0.0000\n",
      "Score (max over agents) from episode 2: 0.0000\n",
      "Score (max over agents) from episode 3: 0.1000\n",
      "Score (max over agents) from episode 4: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    j = 0\n",
    "    while True:\n",
    "        j += 1\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        # print('Rewards from step {}: {:.2f},{:.2f}'.format(i, rewards[0], rewards[1]))\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += rewards                                  # update the score (for each agent)\n",
    "        # print('\\t {:.2f},{:.2f}'.format( scores[0],scores[1]))\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {:.4f}'.format(i, np.max(scores)))\n",
    "    # print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Local Libraries\n",
    "- Multi-Agent Actor-Critic Deep Deterministic Policy from **maddpg.py** imports single agents from **ddpg.py** and eploratory noise process from **OUNoise.py**  \n",
    "- Experiences are stored adn sampled from **replaybuffer.py**\n",
    "- Other utilies functions imported from **utilities.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent\n",
    "from maddpg import MADDPG\n",
    "# Replay Buffer\n",
    "from replaybuffer import ReplayBuffer\n",
    "# Utilities\n",
    "from utilities import seeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Target Reward\n",
    "    tgt_score = 0.5\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Seed\n",
    "    seed = 2\n",
    "    seeding(seed)\n",
    "    # Model Architecture\n",
    "    # Actor\n",
    "    hidden_in_actor = 256\n",
    "    hidden_out_actor = 128\n",
    "    lr_actor = 1e-4\n",
    "    # Critic\n",
    "    hidden_in_critic = 256\n",
    "    hidden_out_critic = 128\n",
    "    lr_critic = 3e-4\n",
    "    weight_decay_critic = 0\n",
    "    # Episodes\n",
    "    number_of_episodes = 10000\n",
    "    episode_length = 2000\n",
    "    # Buffer\n",
    "    buffer_size = int(1e6)\n",
    "    batchsize = 512\n",
    "    # Agent Update Frequency\n",
    "    episode_per_update = 1\n",
    "    # Rewards Discounts Factor\n",
    "    discount_factor = 1\n",
    "    # Soft Update Weight\n",
    "    tau = 0.02\n",
    "    # Noise Process\n",
    "    noise_factor = 2\n",
    "    noise_reduction = 0.9999\n",
    "    noise_floor = 0.1\n",
    "    # Window\n",
    "    win_len = 100\n",
    "    # Save Frequency\n",
    "    save_interval = 200\n",
    "    # Logger\n",
    "    log_path = os.getcwd()+\"/log\"\n",
    "    logger = SummaryWriter(log_dir=log_path)\n",
    "    # Model Directory\n",
    "    model_dir = os.getcwd()+\"/model_dir\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Load Saved Model\n",
    "    load_model = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain Name: TennisBrain\n",
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n"
     ]
    }
   ],
   "source": [
    "    # env = UnityEnvironment(file_name=\"./Tennis_Linux_NoVis/Tennis.x86_64\")\n",
    "    # Get brain\n",
    "    brain_name = env.brain_names[0]\n",
    "    brain = env.brains[brain_name]\n",
    "    print('Brain Name:', brain_name)\n",
    "    # Reset the environment\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    # Number of Agents\n",
    "    num_agents = len(env_info.agents)\n",
    "    print('Number of agents:', num_agents)\n",
    "    # size of each action\n",
    "    action_size = brain.vector_action_space_size\n",
    "    print('Size of each action:', action_size)\n",
    "    # examine the state space\n",
    "    states = env_info.vector_observations\n",
    "    state_size = states.shape[1]\n",
    "    print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Multi Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    maddpg = MADDPG(state_size, action_size, num_agents,\n",
    "                    hidden_in_actor, hidden_out_actor, lr_actor,\n",
    "                    hidden_in_critic, hidden_out_critic, lr_critic, weight_decay_critic,\n",
    "                    discount_factor, tau, seed, device)\n",
    "\n",
    "    if load_model:\n",
    "        load_dict_list = torch.load(os.path.join(model_dir, 'episode-saved.pt'))\n",
    "        for i in range(num_agents):\n",
    "            maddpg.maddpg_agent[i].actor.load_state_dict(load_dict_list[i]['actor_params'])\n",
    "            maddpg.maddpg_agent[i].actor_optimizer.load_state_dict(load_dict_list[i]['actor_optim_params'])\n",
    "            maddpg.maddpg_agent[i].critic.load_state_dict(load_dict_list[i]['critic_params'])\n",
    "            maddpg.maddpg_agent[i].critic_optimizer.load_state_dict(load_dict_list[i]['critic_optim_params'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuffer = ReplayBuffer(buffer_size, seed, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 0/10000   0% ETA:  --:--:-- |                                       | \r"
     ]
    }
   ],
   "source": [
    "    widget = ['episode: ', pb.Counter(), '/', str(number_of_episodes), ' ',\n",
    "              pb.Percentage(), ' ', pb.ETA(), ' ', pb.Bar(marker=pb.RotatingMarker()), ' ']\n",
    "    timer = pb.ProgressBar(widgets=widget, maxval=number_of_episodes).start()\n",
    "    start = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAY and LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 0/10000   0% ETA:  --:--:-- |                                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 0.0 \t Update Count 0 \t Last Episode t 13 \n",
      "Episode 0 \tAverage Score: 0.00 \tNoise Factor 1.999800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 199/10000   1% ETA:  0:17:22 |                                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 0.4 \t Update Count 170 \t Last Episode t 13 \n",
      "Episode 200 \tAverage Score: 0.01 \tNoise Factor 1.960199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 399/10000   3% ETA:  0:16:30 |\\                                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 0.7 \t Update Count 370 \t Last Episode t 14 \n",
      "Episode 400 \tAverage Score: 0.00 \tNoise Factor 1.921383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 601/10000   6% ETA:  0:16:27 |||                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 1.0 \t Update Count 570 \t Last Episode t 13 \n",
      "Episode 600 \tAverage Score: 0.01 \tNoise Factor 1.883335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 795/10000   7% ETA:  0:16:03 |\\\\\\                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 1.4 \t Update Count 770 \t Last Episode t 14 \n",
      "Episode 800 \tAverage Score: 0.00 \tNoise Factor 1.846041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 998/10000   9% ETA:  0:15:40 |\\\\\\                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 1.7 \t Update Count 970 \t Last Episode t 13 \n",
      "Episode 1000 \tAverage Score: 0.00 \tNoise Factor 1.809485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1201/10000  12% ETA:  0:15:16 |\\\\\\\\                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 2.1 \t Update Count 1170 \t Last Episode t 13 \n",
      "Episode 1200 \tAverage Score: 0.00 \tNoise Factor 1.773653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1400/10000  14% ETA:  0:15:07 ||||||                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 2.5 \t Update Count 1370 \t Last Episode t 13 \n",
      "Episode 1400 \tAverage Score: 0.02 \tNoise Factor 1.738530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1601/10000  16% ETA:  0:15:15 |/////                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 2.9 \t Update Count 1570 \t Last Episode t 14 \n",
      "Episode 1600 \tAverage Score: 0.05 \tNoise Factor 1.704104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1797/10000  17% ETA:  0:15:25 |\\\\\\\\\\\\                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 3.4 \t Update Count 1770 \t Last Episode t 13 \n",
      "Episode 1800 \tAverage Score: 0.06 \tNoise Factor 1.670358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1996/10000  19% ETA:  0:15:35 |\\\\\\\\\\\\\\                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 3.9 \t Update Count 1970 \t Last Episode t 29 \n",
      "Episode 2000 \tAverage Score: 0.07 \tNoise Factor 1.637281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2198/10000  21% ETA:  0:15:48 |--------                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 4.5 \t Update Count 2170 \t Last Episode t 29 \n",
      "Episode 2200 \tAverage Score: 0.08 \tNoise Factor 1.604859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2401/10000  24% ETA:  0:15:53 |////////                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 5.0 \t Update Count 2370 \t Last Episode t 30 \n",
      "Episode 2400 \tAverage Score: 0.08 \tNoise Factor 1.573080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2597/10000  25% ETA:  0:15:51 |\\\\\\\\\\\\\\\\\\                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 5.6 \t Update Count 2570 \t Last Episode t 53 \n",
      "Episode 2600 \tAverage Score: 0.08 \tNoise Factor 1.541929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2798/10000  27% ETA:  0:15:45 |----------                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 6.1 \t Update Count 2770 \t Last Episode t 29 \n",
      "Episode 2800 \tAverage Score: 0.08 \tNoise Factor 1.511395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2997/10000  29% ETA:  0:15:37 |///////////                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 6.7 \t Update Count 2970 \t Last Episode t 13 \n",
      "Episode 3000 \tAverage Score: 0.08 \tNoise Factor 1.481466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3198/10000  31% ETA:  0:15:27 |///////////                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 7.3 \t Update Count 3170 \t Last Episode t 30 \n",
      "Episode 3200 \tAverage Score: 0.09 \tNoise Factor 1.452130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3401/10000  34% ETA:  0:15:16 |------------                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 7.9 \t Update Count 3370 \t Last Episode t 13 \n",
      "Episode 3400 \tAverage Score: 0.09 \tNoise Factor 1.423374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3601/10000  36% ETA:  0:15:04 |\\\\\\\\\\\\\\\\\\\\\\\\\\                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 8.5 \t Update Count 3570 \t Last Episode t 12 \n",
      "Episode 3600 \tAverage Score: 0.09 \tNoise Factor 1.395188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3799/10000  37% ETA:  0:14:52 |//////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 9.1 \t Update Count 3770 \t Last Episode t 43 \n",
      "Episode 3800 \tAverage Score: 0.10 \tNoise Factor 1.367560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3999/10000  39% ETA:  0:14:40 |//////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 9.8 \t Update Count 3970 \t Last Episode t 52 \n",
      "Episode 4000 \tAverage Score: 0.10 \tNoise Factor 1.340479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 4199/10000  41% ETA:  0:14:29 |---------------                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 10.5 \t Update Count 4170 \t Last Episode t 29 \n",
      "Episode 4200 \tAverage Score: 0.10 \tNoise Factor 1.313935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 4401/10000  44% ETA:  0:14:09 |||||||||||||||||                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 11.1 \t Update Count 4370 \t Last Episode t 30 \n",
      "Episode 4400 \tAverage Score: 0.09 \tNoise Factor 1.287916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 4598/10000  45% ETA:  0:13:48 |-----------------                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 11.8 \t Update Count 4570 \t Last Episode t 87 \n",
      "Episode 4600 \tAverage Score: 0.09 \tNoise Factor 1.262412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 4798/10000  47% ETA:  0:13:32 ||||||||||||||||||                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 12.5 \t Update Count 4770 \t Last Episode t 70 \n",
      "Episode 4800 \tAverage Score: 0.10 \tNoise Factor 1.237413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 4999/10000  49% ETA:  0:13:15 |||||||||||||||||||                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 13.3 \t Update Count 4970 \t Last Episode t 51 \n",
      "Episode 5000 \tAverage Score: 0.10 \tNoise Factor 1.212910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 5200/10000  52% ETA:  0:13:00 ||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 14.1 \t Update Count 5170 \t Last Episode t 13 \n",
      "Episode 5200 \tAverage Score: 0.12 \tNoise Factor 1.188891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 5400/10000  54% ETA:  0:12:50 |-------------------                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 15.1 \t Update Count 5370 \t Last Episode t 86 \n",
      "Episode 5400 \tAverage Score: 0.14 \tNoise Factor 1.165348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 5599/10000  55% ETA:  0:12:43 |--------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 16.2 \t Update Count 5570 \t Last Episode t 29 \n",
      "Episode 5600 \tAverage Score: 0.16 \tNoise Factor 1.142272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 5800/10000  58% ETA:  0:12:24 |---------------------                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 17.1 \t Update Count 5770 \t Last Episode t 13 \n",
      "Episode 5800 \tAverage Score: 0.14 \tNoise Factor 1.119652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 6000/10000  60% ETA:  0:12:18 |----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 18.5 \t Update Count 5970 \t Last Episode t 61 \n",
      "Episode 6000 \tAverage Score: 0.19 \tNoise Factor 1.097481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 6201/10000  62% ETA:  0:12:00 |//////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 19.6 \t Update Count 6170 \t Last Episode t 169 \n",
      "Episode 6200 \tAverage Score: 0.17 \tNoise Factor 1.075748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 6399/10000  63% ETA:  0:11:36 ||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 20.6 \t Update Count 6370 \t Last Episode t 29 \n",
      "Episode 6400 \tAverage Score: 0.15 \tNoise Factor 1.054446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 6599/10000  65% ETA:  0:11:16 |////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 21.9 \t Update Count 6570 \t Last Episode t 30 \n",
      "Episode 6600 \tAverage Score: 0.20 \tNoise Factor 1.033565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 6800/10000  68% ETA:  0:10:55 ||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 23.2 \t Update Count 6770 \t Last Episode t 34 \n",
      "Episode 6800 \tAverage Score: 0.20 \tNoise Factor 1.013098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 7001/10000  70% ETA:  0:10:34 |-------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 24.7 \t Update Count 6970 \t Last Episode t 54 \n",
      "Episode 7000 \tAverage Score: 0.23 \tNoise Factor 0.993037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 7199/10000  71% ETA:  0:10:10 |--------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 26.1 \t Update Count 7170 \t Last Episode t 29 \n",
      "Episode 7200 \tAverage Score: 0.24 \tNoise Factor 0.973372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 7400/10000  74% ETA:  0:09:44 ||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 27.7 \t Update Count 7370 \t Last Episode t 140 \n",
      "Episode 7400 \tAverage Score: 0.25 \tNoise Factor 0.954097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 7601/10000  76% ETA:  0:09:24 |||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 29.8 \t Update Count 7570 \t Last Episode t 178 \n",
      "Episode 7600 \tAverage Score: 0.34 \tNoise Factor 0.935204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 7801/10000  78% ETA:  0:09:08 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 32.5 \t Update Count 7770 \t Last Episode t 164 \n",
      "Episode 7800 \tAverage Score: 0.43 \tNoise Factor 0.916685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 8001/10000  80% ETA:  0:08:48 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 35.2 \t Update Count 7970 \t Last Episode t 29 \n",
      "Episode 8000 \tAverage Score: 0.46 \tNoise Factor 0.898532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 8200/10000  82% ETA:  0:08:28 |//////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 38.6 \t Update Count 8170 \t Last Episode t 159 \n",
      "Episode 8200 \tAverage Score: 0.58 \tNoise Factor 0.880739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 8401/10000  84% ETA:  0:07:58 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 41.9 \t Update Count 8370 \t Last Episode t 709 \n",
      "Episode 8400 \tAverage Score: 0.54 \tNoise Factor 0.863298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 8601/10000  86% ETA:  0:07:21 ||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 45.3 \t Update Count 8570 \t Last Episode t 119 \n",
      "Episode 8600 \tAverage Score: 0.57 \tNoise Factor 0.846203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 8799/10000  87% ETA:  0:06:40 |////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 48.9 \t Update Count 8770 \t Last Episode t 29 \n",
      "Episode 8800 \tAverage Score: 0.61 \tNoise Factor 0.829446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 9001/10000  90% ETA:  0:05:48 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 52.4 \t Update Count 8970 \t Last Episode t 279 \n",
      "Episode 9000 \tAverage Score: 0.58 \tNoise Factor 0.813021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 9200/10000  92% ETA:  0:04:54 |//////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 56.5 \t Update Count 9170 \t Last Episode t 89 \n",
      "Episode 9200 \tAverage Score: 0.70 \tNoise Factor 0.796922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 9400/10000  94% ETA:  0:03:52 |//////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 60.7 \t Update Count 9370 \t Last Episode t 76 \n",
      "Episode 9400 \tAverage Score: 0.72 \tNoise Factor 0.781141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 9600/10000  96% ETA:  0:02:43 |-----------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 65.5 \t Update Count 9570 \t Last Episode t 18 \n",
      "Episode 9600 \tAverage Score: 0.81 \tNoise Factor 0.765672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 9801/10000  98% ETA:  0:01:26 |------------------------------------ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 70.8 \t Update Count 9770 \t Last Episode t 140 \n",
      "Episode 9800 \tAverage Score: 0.92 \tNoise Factor 0.750510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 10000/10000 100% Time: 1:15:41 |||||||||||||||||||||||||||||||||||||| \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 75.7 \t Update Count 9969 \t Last Episode t 36 \n",
      "Episode 9999 \tAverage Score: 0.83 \tNoise Factor 0.735722\n",
      "\n",
      "Elapsed time 75.7 \t Update Count 9969 \t Last Episode t 36 \n",
      "Episode 9999 \tAverage Score: 0.83 \tNoise Factor 0.735722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "    # initialize scores\n",
    "    scores_history = []\n",
    "    scores_window = deque(maxlen=save_interval)\n",
    "\n",
    "    # i_episode = 0\n",
    "    for i_episode in range(number_of_episodes):\n",
    "        timer.update(i_episode)\n",
    "\n",
    "        # Reset Environmet\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agents)\n",
    "\n",
    "        # Reset Agent\n",
    "        maddpg.reset()\n",
    "\n",
    "        # episode_t = 0\n",
    "        for episode_t in range(episode_length):\n",
    "\n",
    "            # Explore with decaying noise factor\n",
    "            actions = maddpg.act(states, noise_factor=noise_factor)\n",
    "            env_info = env.step(actions)[brain_name]             # Environment reacts\n",
    "            next_states = env_info.vector_observations           # get the next states\n",
    "            rewards = env_info.rewards                           # get the rewards\n",
    "            dones = env_info.local_done                          # see if episode has finished\n",
    "\n",
    "            ###################\n",
    "            # Save Experience #\n",
    "            ###################\n",
    "            rebuffer.add(states, actions, rewards, next_states, dones)\n",
    "\n",
    "            scores += rewards\n",
    "            states = next_states\n",
    "\n",
    "            if any(dones):\n",
    "                break\n",
    "\n",
    "        scores_history.append(np.max(scores))       # save most recent score\n",
    "        scores_window.append(np.max(scores))        # save most recent score\n",
    "        avg_rewards = np.mean(scores_window)\n",
    "        noise_factor = max(noise_floor, noise_factor*noise_reduction)    # Reduce Noise Factor\n",
    "\n",
    "        #########\n",
    "        # LEARN #\n",
    "        #########\n",
    "        # Update Every episode_per_update\n",
    "        if len(rebuffer) > batchsize and i_episode % episode_per_update == 0:\n",
    "            for a_i in range(num_agents):\n",
    "                samples = rebuffer.sample(batchsize)\n",
    "                maddpg.update(samples, a_i, logger)\n",
    "            # Soft Update\n",
    "            maddpg.update_targets()\n",
    "\n",
    "        ##################\n",
    "        # Track Progress #\n",
    "        ##################\n",
    "        if i_episode % save_interval == 0 or i_episode == number_of_episodes-1:\n",
    "            logger.add_scalars('rewards', {'Avg Reward': avg_rewards, 'Noise Factor': noise_factor}, i_episode)\n",
    "            print('\\nElapsed time {:.1f} \\t Update Count {} \\t Last Episode t {}'.format((time.time() - start)/60, maddpg.update_count, episode_t),\n",
    "                  '\\nEpisode {} \\tAverage Score: {:.2f} \\tNoise Factor {:2f}'.format(i_episode, avg_rewards, noise_factor), end=\"\\n\")\n",
    "\n",
    "        ##############\n",
    "        # Save Model #\n",
    "        ##############\n",
    "        save_info = ((i_episode) % save_interval == 0 or i_episode == (number_of_episodes-1))\n",
    "        if save_info:\n",
    "            save_dict_list = []\n",
    "            for i in range(num_agents):\n",
    "                save_dict = {'actor_params': maddpg.maddpg_agent[i].actor.state_dict(),\n",
    "                             'actor_optim_params': maddpg.maddpg_agent[i].actor_optimizer.state_dict(),\n",
    "                             'critic_params': maddpg.maddpg_agent[i].critic.state_dict(),\n",
    "                             'critic_optim_params': maddpg.maddpg_agent[i].critic_optimizer.state_dict()}\n",
    "                save_dict_list.append(save_dict)\n",
    "            torch.save(save_dict_list, os.path.join(model_dir, 'episode-Latest.pt'))\n",
    "\n",
    "            pd.Series(scores_history).to_csv(os.path.join(model_dir, \"scores.csv\"))\n",
    "\n",
    "            # plot the scores\n",
    "            rolling_mean = pd.Series(scores_history).rolling(win_len).mean()\n",
    "            fig = plt.figure()\n",
    "            # ax = fig.add_subplot(111)\n",
    "            plt.plot(np.arange(len(scores_history)), scores_history)\n",
    "            plt.axhline(y=tgt_score, color='r', linestyle='dashed')\n",
    "            plt.plot(rolling_mean, lw=3)\n",
    "            plt.ylabel('Score')\n",
    "            plt.xlabel('Episode #')\n",
    "            # plt.show()\n",
    "            fig.savefig(os.path.join(model_dir, 'Average_Score.pdf'))\n",
    "            fig.savefig(os.path.join(model_dir, 'Average_Score.jpg'))\n",
    "            plt.close()\n",
    "\n",
    "        if (avg_rewards > tgt_score * 3) or i_episode == (number_of_episodes-1):\n",
    "            logger.add_scalars('rewards', {'Avg Reward': avg_rewards, 'Noise Factor': noise_factor}, i_episode)\n",
    "            print('\\nElapsed time {:.1f} \\t Update Count {} \\t Last Episode t {}'.format((time.time() - start)/60, maddpg.update_count, episode_t),\n",
    "                  '\\nEpisode {} \\tAverage Score: {:.2f} \\tNoise Factor {:2f}'.format(i_episode, avg_rewards, noise_factor), end=\"\\n\")\n",
    "            break\n",
    "\n",
    "    # env.close()\n",
    "    logger.close()\n",
    "    timer.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995.0</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996.0</th>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997.0</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998.0</th>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999.0</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score\n",
       "9995.0   0.09\n",
       "9996.0   0.39\n",
       "9997.0   0.10\n",
       "9998.0   2.60\n",
       "9999.0   0.10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_history = pd.read_csv(os.path.join(model_dir, \"scores.csv\"), index_col=0, header=None, names =['Score'])\n",
    "scores_history.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995.0</th>\n",
       "      <td>0.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996.0</th>\n",
       "      <td>0.8446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997.0</th>\n",
       "      <td>0.8266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998.0</th>\n",
       "      <td>0.8366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999.0</th>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Score\n",
       "9995.0  0.8507\n",
       "9996.0  0.8446\n",
       "9997.0  0.8266\n",
       "9998.0  0.8366\n",
       "9999.0  0.8116"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_mean = scores_history.rolling(win_len).mean()\n",
    "rolling_mean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores_history)), scores_history)\n",
    "plt.axhline(y=tgt_score, color='r', linestyle='dashed')\n",
    "plt.plot(rolling_mean, lw=3)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "# plt.show()\n",
    "fig.savefig(os.path.join(model_dir, 'Average_Score_Final.pdf'))\n",
    "fig.savefig(os.path.join(model_dir, 'Average_Score_Final.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAY SMART AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=True\n",
    "if load_model:\n",
    "    load_dict_list = torch.load(os.path.join(model_dir, 'episode-Latest.pt'))\n",
    "    for i in range(num_agents):\n",
    "        maddpg.maddpg_agent[i].actor.load_state_dict(load_dict_list[i]['actor_params'])\n",
    "        maddpg.maddpg_agent[i].actor_optimizer.load_state_dict(load_dict_list[i]['actor_optim_params'])\n",
    "        maddpg.maddpg_agent[i].critic.load_state_dict(load_dict_list[i]['critic_params'])\n",
    "        maddpg.maddpg_agent[i].critic_optimizer.load_state_dict(load_dict_list[i]['critic_optim_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")\n",
    "# brain_name = env.brain_names[0]\n",
    "# brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 0: 0.2000\n",
      "Score (max over agents) from episode 1: 0.3000\n",
      "Score (max over agents) from episode 2: 0.0900\n"
     ]
    }
   ],
   "source": [
    "## Play \n",
    "for i in range(3):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    states = env_info.vector_observations\n",
    "    scores = np.zeros(num_agents)\n",
    "    for j in range(200):\n",
    "        actions = maddpg.act(states)\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_states = env_info.vector_observations    # get the next state\n",
    "        rewards = env_info.rewards                    # get the reward\n",
    "        dones = env_info.local_done                   # see if episode has finished\n",
    "        scores += rewards                             # update the score\n",
    "        states = next_states                          # roll over the state to next time step\n",
    "        if np.any(dones):\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {:.4f}'.format(i, np.max(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
